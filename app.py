import streamlit as st
import time
import os

# ConfiguraciÃ³n
st.set_page_config(
    page_title="Asistente 4 Materias + BÃºsqueda",
    page_icon="ğŸ“",
    layout="wide"
)

# TÃ­tulo
st.title("ğŸ“ Asistente 4 Materias + BÃºsqueda SemÃ¡ntica")
st.markdown("### Ahora con bÃºsqueda inteligente en tu material")

# ConfiguraciÃ³n de materias
MATERIAS = {
    "estadistica": {
        "nombre": "EstadÃ­stica",
        "emoji": "ğŸ“Š",
        "profesor": "Prof. Ferrarre",
        "consejo": "Practica todos los ejercicios y enfÃ³cate en el proceso paso a paso"
    },
    "desarrollo_ia": {
        "nombre": "Desarrollo de IA", 
        "emoji": "ğŸ¤–",
        "profesor": "Especialista IA",
        "consejo": "Entiende los fundamentos antes de usar frameworks complejos"
    },
    "campo_laboral": {
        "nombre": "Campo Laboral",
        "emoji": "ğŸ’¼",
        "profesor": "Prof. Acri",
        "consejo": "SÃ© profesional, puntual y prepara exhaustivamente tus entregas"
    },
    "comunicacion": {
        "nombre": "ComunicaciÃ³n",
        "emoji": "ğŸ¯", 
        "profesor": "Especialista ComunicaciÃ³n",
        "consejo": "Estructura tus mensajes y adapta tu lenguaje al pÃºblico"
    }
}

# Sidebar
with st.sidebar:
    st.header("ğŸ“š Selecciona Materia")
    
    materia_seleccionada = st.selectbox(
        "Elige:",
        list(MATERIAS.keys()),
        format_func=lambda x: f"{MATERIAS[x]['emoji']} {MATERIAS[x]['nombre']}"
    )
    
    materia = MATERIAS[materia_seleccionada]
    st.subheader(f"{materia['emoji']} {materia['profesor']}")
    st.write(f"**Consejo:** {materia['consejo']}")
    
    st.markdown("---")
    
    if st.button("ğŸ§¹ Limpiar Chat"):
        st.session_state.messages = []
        st.rerun()

# Cargar base de conocimiento con bÃºsqueda semÃ¡ntica
@st.cache_resource
def cargar_busqueda_semantica():
    """Cargar sistema de bÃºsqueda semÃ¡ntica"""
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings
        from langchain.vectorstores import FAISS
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain.schema import Document

        # Verificar carpeta conocimiento
        if not os.path.exists("conocimiento"):
            st.error("âŒ No se encuentra la carpeta 'conocimiento'")
            return None

        # Cargar embeddings (esto funciona sin torch pesado)
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )

        # Cargar documentos
        documentos = []
        for materia_dir in os.listdir("conocimiento"):
            materia_path = os.path.join("conocimiento", materia_dir)
            if os.path.isdir(materia_path):
                for archivo in os.listdir(materia_path):
                    if archivo.endswith('.txt'):
                        archivo_path = os.path.join(materia_path, archivo)
                        try:
                            with open(archivo_path, 'r', encoding='utf-8') as f:
                                contenido = f.read()
                                documentos.append(
                                    Document(
                                        page_content=contenido,
                                        metadata={"materia": materia_dir, "archivo": archivo}
                                    )
                                )
                        except Exception as e:
                            continue

        if not documentos:
            st.error("âŒ No se encontraron documentos")
            return None

        # Procesar documentos
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=150
        )
        documentos_divididos = text_splitter.split_documents(documentos)

        # Crear vectorstore
        vectorstore = FAISS.from_documents(documentos_divididos, embeddings)
        st.success(f"âœ… BÃºsqueda semÃ¡ntica activada: {len(documentos)} documentos indexados")
        return vectorstore

    except Exception as e:
        st.error(f"âŒ Error en bÃºsqueda semÃ¡ntica: {e}")
        return None

# Cargar sistema de bÃºsqueda
with st.spinner("ğŸ”„ Activando bÃºsqueda inteligente..."):
    buscador = cargar_busqueda_semantica()

# Inicializar chat
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": f"Â¡Hola! Soy tu asistente para {materia['nombre']}. Ahora puedo buscar en todo tu material. ğŸ“"}
    ]

# Mostrar historial de chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# FunciÃ³n de bÃºsqueda mejorada
def buscar_respuesta_inteligente(pregunta, materia):
    """Buscar respuesta en el material con contexto especÃ­fico"""
    if buscador is None:
        return "Sistema de bÃºsqueda no disponible", []
    
    try:
        # Buscar documentos relevantes
        documentos = buscador.similarity_search(pregunta, k=3)
        
        # Filtrar por materia si hay coincidencias
        docs_materia = [doc for doc in documentos if doc.metadata.get("materia") == materia]
        
        # Usar todos si no hay de la materia especÃ­fica
        documentos_usar = docs_materia if docs_materia else documentos
        
        if not documentos_usar:
            return "No encontrÃ© informaciÃ³n especÃ­fica para tu pregunta en el material disponible.", []
        
        # Construir respuesta contextual
        contexto = "\n\n".join([doc.page_content for doc in documentos_usar])
        
        # Generar respuesta basada en el contexto
        respuesta_base = f"""
**ğŸ” EncontrÃ© esta informaciÃ³n relevante en el material de {MATERIAS[materia]['nombre']}:**

{contexto}

**ğŸ’¡ Mi anÃ¡lisis:**
BasÃ¡ndome en el material, puedo ver que esta informaciÃ³n es relevante para tu pregunta sobre "{pregunta}".

**ğŸ¯ Consejo prÃ¡ctico:**
{MATERIAS[materia]['consejo']}
"""
        
        return respuesta_base, documentos_usar
        
    except Exception as e:
        return f"Error en bÃºsqueda: {str(e)}", []

# Input del usuario
if prompt := st.chat_input(f"Pregunta sobre {materia['nombre']}..."):
    # Agregar mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Buscar y generar respuesta
    with st.chat_message("assistant"):
        with st.spinner("ğŸ” Buscando en el material..."):
            respuesta, documentos_encontrados = buscar_respuesta_inteligente(prompt, materia_seleccionada)
            
            # Efecto de escritura
            placeholder = st.empty()
            respuesta_completa = ""
            
            for chunk in respuesta.split():
                respuesta_completa += chunk + " "
                time.sleep(0.02)
                placeholder.markdown(respuesta_completa + "â–Œ")
            
            placeholder.markdown(respuesta_completa)
            
            # Mostrar fuentes si hay documentos encontrados
            if documentos_encontrados:
                with st.expander("ğŸ“ Ver fuentes encontradas"):
                    for i, doc in enumerate(documentos_encontrados):
                        st.write(f"**Fuente {i+1}:** {doc.metadata.get('archivo', 'Desconocido')}")
                        st.write(f"*Materia:* {doc.metadata.get('materia', 'General')}")
    
    st.session_state.messages.append({"role": "assistant", "content": respuesta_completa})

# InformaciÃ³n del estado
st.markdown("---")
st.success("""
**ğŸ‰ Â¡BÃºsqueda SemÃ¡ntica Activada!**

**âœ… Nuevas Capacidades:**
- ğŸ” BÃºsqueda inteligente en TODO tu material
- ğŸ“š IndexaciÃ³n automÃ¡tica de documentos
- ğŸ¯ Respuestas contextuales especÃ­ficas
- ğŸ“ VisualizaciÃ³n de fuentes encontradas

**ğŸš€ PrÃ³ximo Paso: IA Generativa**
- Una vez confirmado que la bÃºsqueda funciona
- Agregaremos el modelo de lenguaje para respuestas mÃ¡s naturales
- Mantendremos la bÃºsqueda semÃ¡ntica como base

**ğŸ’¡ CÃ³mo probar:**
- Pregunta sobre temas especÃ­ficos de tus materias
- Usa palabras clave de tus archivos
- Verifica que encuentre informaciÃ³n relevante
""")

st.markdown("---")
st.markdown("ğŸ“ **Asistente 4 Materias + BÃºsqueda SemÃ¡ntica** â€¢ Streamlit Cloud")
